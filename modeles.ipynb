{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Les differents types de système de recommandation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\"\"\"\n",
    "Il existe deux type de recommanders:\n",
    "    -Le content Based: on va pas l'utiliser vu qu'on n'a pas les caractéristiques de chaque item et de chaque utilisateur\n",
    "    -Le Collaboratif Filtering: qui se base sur la note attribué par l'utilisateur sur l'item. \n",
    "Il existe deux type de recommanders CF:\n",
    "    -Memory Based:\n",
    "    -Model Based:\n",
    "Pour le modèle Memory Based, on a utilisé le modèle user based et item based pour les métriques \"cosine similarity\" et \"cityblock\"\n",
    "Pour le modèle Mode Based, on a utilisé les svds et les gradient stochastique descendant pour l'améliorer. \n",
    "\"\"\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(9001)\n",
    "#pour avoir toujours les memes erreurs à chaque fois qu'on re exécute le projet."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\"\"\"\n",
    "Python n'a pas réussi à créer des matrices avec 7636 lignes et 1264 colonnes (pour construire la matrice de user-item)\n",
    "C'est pour cela on a voulu expliqué et résoulut le problème dans un cas de jeu de données plus petit dis on de l'ordre 100.000 au lieu de 10.000.000\n",
    "A la fin on a rèssit à résoudre le problème avec tout le jeu de donnés.\n",
    "On a apperçu que la base de données présente les notes utilisateur par utilisateur. Donc c'est on prend aléatoirement 100.000 observation\n",
    "aléatoirement de la base, on peut tomber sur le meme problème vu qu'on peut ne pas réduire vraiment le nombre des utilisateurs et le nombre des items.\n",
    "Pour ça on a décidé de travailler sur les premiers 100.000 lignes.\n",
    "\"\"\"\n",
    "\n",
    "tab = pd.read_csv('ratings.csv',nrows=100001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le nombre des utilisateurs est :730 Et le nombre des items est: 6373\n"
     ]
    }
   ],
   "source": [
    "useri,frequsers=np.unique(tab.User_ID,return_counts=True)#useri les id des users, frequsers les freq de chaque user\n",
    "itemi,freqitems=np.unique(tab.Item_ID,return_counts=True)#itemi les id des item, freqitem les freq de chaque item\n",
    "n_users=len(useri)\n",
    "n_items=len(itemi)\n",
    "print(\"le nombre des utilisateurs est :\"+ str(n_users) + \" Et le nombre des items est: \"+ str(n_items))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Un des problèmes qu'on a rencontré était le fait que les ids des users et des items n'était pas ordonnée.\n",
    "C'est à dire on peut trouver l'utilisateur 1,2,3,5 et 8 sans trouver les utilisateurs 4 ,6 et 7. \n",
    "Ceci nous a posé un problème dans la création de la matrice user-item parce que on risque d'avoir plusieurs lignes et colonnes vides.\n",
    "Pour ça, on a crée un tableau indice_user et un tableau indice_item qui contiennent les anciens id et les nouvelles id \n",
    "par expl (1,2,5,6)=>(1,2,3,4) puis on a ajouté deux colonnes sur le tableau principale qui contient ces nouveaux IDs.\n",
    "(ps) ce traitement est très couteux, ça nous a pris presque 6 minutes pour seulement 100.000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "indice_user = pd.DataFrame()\n",
    "indice_user[\"indice\"]=range(1,len(useri)+1)\n",
    "indice_user[\"useri\"]=useri\n",
    "\n",
    "\n",
    "indice_item = pd.DataFrame()\n",
    "indice_item[\"indice\"]=range(1,len(itemi)+1)\n",
    "indice_item[\"itemi\"]=itemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#créer user_ID_new et Item_ID_new\n",
    "x=[]\n",
    "y=[]\n",
    "for i in range(0,len(tab)):\n",
    "    x.append((indice_user.indice[indice_user.useri==tab.User_ID[i]].axes[0]+1)[0])\n",
    "    y.append((indice_item.indice[indice_item.itemi==tab.Item_ID[i]].axes[0]+1)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tab[\"User_ID_new\"]=x\n",
    "tab[\"Item_ID_new\"]=y\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Pour faire la validation croisé, on a voulut faire une répartition avec la variable date.\n",
    "Par exemple on va prendre une date et on va dire tous les événements avant cette date vont construire la base d'apprentissage \n",
    "et tous les evenemtns après cette date vont construire la base de teste.\n",
    "Le problème qu'on a rencontré est le fait que la base de données est répartie avec un ordre plus +/- chronlogique.\n",
    "C'est à dire tous les événements d'un utilisateur 4 sont faites avant les événements de l'utilisateur 5 . \n",
    "Donc, si on raisonne avec une date au milieu on va obtenir un train avec des info sur des utilisateurs, et la matrice test avec \n",
    "d'autres utilisateurs surlesquelles on n'a pas d'informations ce qui aboutira à des mauvaises prédictions.\n",
    "Une autre idée était de mettre 80% des premiers observation pour chaque utilisateru dans la base train et le reste dans la base test\n",
    "Avec ça on aura une répartition idéale. mais on n'a pas réussi à faire ça pour la contrainte du temps.\n",
    "Donc on a fait un simple train_test_split\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn import cross_validation as cv\n",
    "train_data, test_data = cv.train_test_split(tab[[\"User_ID_new\",\"Item_ID_new\",\"rating\"]], test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\"\"\"\n",
    "La régle dit que si on a une grande sparsity (ou bien rareté des données, c'est de ne pas arriver à calculer la \n",
    "similarité entre 2 utilisateurs par expl si chaqu'un a aimé different items que l'autre), les modèles Model Based seront les plus efficace.\n",
    "Calculant alors la sparsity:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of our data base is 97.9%\n"
     ]
    }
   ],
   "source": [
    "sparsity=round(1.0-len(tab)/float(n_users*n_items),3)\n",
    "print 'The sparsity level of our data base is ' +  str(sparsity*100) + '%'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\"\"\"\n",
    "La pourcentage de sparsity est bien grande donc, on peut confirmer dés maintenant que les modèles Model Based seront les \n",
    "modèles les plus efficaces.\n",
    "Commen\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.le Memory based Collaboratif Filtering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 La mise en place du modèle:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "On va commencer par créer les modèles Memory based.\n",
    "    -Les modèles User-Based : \"Les utilisateurs qui sont similaires à vous, ont aimé aussi ...\"\n",
    "    -Les modèles Item-Based: \"Les utilisateurs qui ont aimé ça, ont aimé aussi ...\"\n",
    "Pour expliquer plus:\n",
    "-le modele User-Based: va prendre un utilisateur, trouve les utilisateur les plus similaires à lui en se basant sur la note, Puis\n",
    "recommande les items aimé par ces utilisateurs(ça prend un user et retourne des items)\n",
    "\n",
    "-Le modele Item-Based:prend un item, cherche les utilisateurs qui ont aimé cet item, trouve les items aimé par ces utilisateurs\n",
    "(ça prend un item et retounes une liste des items)\n",
    "\n",
    "Pour le faire, on utilisé 2 métriques le cosine similaire et cityblock.\n",
    "Pour le faire, on a commencé par créer les matrice user-item train et test. Ce sont les deux matrices qui vont croisé les notes de utilsiateurs et des items.\n",
    "Puis, on a créé nos 4 modèles Memory Based  \n",
    "à la fin, on a créé une fonction pour faire les prédictions selon le modèle\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data_matrix = np.zeros((n_users, n_items))#matrice nulle de longuer tous les users et tous les items\n",
    "for line in train_data.itertuples():#parcourire la ligne col par col\n",
    "    train_data_matrix[line[1]-1, line[2]-1] = line[3] \n",
    "\n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calcule de la cos similarity : (construction du modèle)\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(train_data_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')\n",
    "user_similarity1 = pairwise_distances(train_data_matrix, metric='cityblock')\n",
    "item_similarity1 = pairwise_distances(train_data_matrix.T, metric='cityblock')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):#prend\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)#mean pour chauqe utilisateur (type = float)\n",
    "        #np.newaxis pour convertir mean_user_rating de array de float en array d'array pour l'utiliser avec ratings\n",
    "        #puis on a normalisé la var ratings (rating - E)\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis]) #(type === array comme la var rating)\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)]) \n",
    "        \n",
    "    x = np.zeros((n_users, n_items))\n",
    "    for i in range(0,n_items):\n",
    "        a=max(pred[:,i])\n",
    "        b=min(pred[:,i])\n",
    "        c=0\n",
    "        d=5\n",
    "        for j in range(0,n_users):\n",
    "            x[j,i]=(pred[:,i][j]-(a-c))*d/(b-a+c)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#la prédiction avec les differents modèles:\n",
    "item_prediction = predict(test_data_matrix, item_similarity, type='item')\n",
    "user_prediction = predict(test_data_matrix, user_similarity, type='user')\n",
    "item_prediction1 = predict(test_data_matrix, item_similarity1, type='item')\n",
    "user_prediction1 = predict(test_data_matrix, user_similarity1, type='user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. La comparaison des RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#la creation de la fonction qui calcule le RMSE:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth): #Root Mean Squared Error\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten() \n",
    "    #.flatten() fusionne les elts des array en un array\n",
    "    #on attribue a prediction, les résultats des prédictions où on connait le vrais rating cad:\n",
    "    #prediction: tous nos prédictions sur test; ground_truth.nonzero():les vrais résultats qu'on a dans test\n",
    "    #on va mettre dans prediction les valeurs qu'on a prédit pour les elts qu'on adéja.\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()#pareil dans ground truth\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 1.49898656802\n",
      "Item-based CF RMSE: 1.5177273779\n",
      "User-based1 CF RMSE: 1.49841259116\n",
      "Item-based1 CF RMSE: 1.46078749628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nLe meilleur mod\\xc3\\xa8le est celui qui a le RMSE le plus petit \\nPour notre cas c'\\xc3\\xa9tait Item based pour la m\\xc3\\xa9trique cityblock.\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix))\n",
    "print 'Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix))\n",
    "print 'User-based1 CF RMSE: ' + str(rmse(user_prediction1, test_data_matrix))\n",
    "print 'Item-based1 CF RMSE: ' + str(rmse(item_prediction1, test_data_matrix))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Le meilleur modèle est celui qui a le RMSE le plus petit \n",
    "Pour notre cas c'était Item based pour la métrique cityblock.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Simple comparaison des résultats prédits:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Ici, on va comparer avec l'oeil la difference entre les résultats qu'on a prédit et celle qu'on a réellement:\n",
    "Pour le faire, on va utiliser le meilleur modèle qui est user-cityblock\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Rating</th>\n",
       "      <th>Predicted Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.613519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.741223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.609985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.645600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.529132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.876081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.932248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.789426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.788021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.730687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Rating  Predicted Rating\n",
       "9              4.0          4.613519\n",
       "35             5.0          4.741223\n",
       "36             5.0          4.609985\n",
       "64             4.0          3.645600\n",
       "87             4.0          3.529132\n",
       "128            2.0          2.876081\n",
       "137            5.0          4.932248\n",
       "150            3.0          4.789426\n",
       "161            5.0          4.788021\n",
       "165            5.0          4.730687"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comparaison des prediction de modele  user avec l'oeil:\n",
    "R = pd.DataFrame(test_data_matrix)\n",
    "R_pred=pd.DataFrame(predict(test_data_matrix, item_similarity1, type='item'))\n",
    "# Compare true ratings of item 17 with predictions\n",
    "ratings = pd.DataFrame(data=R.T.loc[16,R.T.loc[16,:] > 0]).head(n=10)\n",
    "ratings['Prediction'] = R_pred.T.loc[16,R.T.loc[16,:] > 0]\n",
    "ratings.columns = ['Actual Rating', 'Predicted Rating']\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 La généralisation de notre meilleur modèle:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Dans un vrais problème, ce qu'on veut faire c'est d'avoir des recommandations pour un utilisateur précis.\n",
    "Pour le faire, on a créé la fonction getrecom qui prend en parametres:\n",
    "    -iduser: l'id d'un utilisateur\n",
    "    -n: nombre de résultat à afficher\n",
    "    -ch=={\"all\"|\"discover\"}: par défaut \"all\", on utilise \"discover\" pour avoir seulement des recommandations sur les \n",
    "    items non notés par l'utilisateur.\n",
    "(ps): on a construit le modele à partir de tout le jeu de données.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#creation du modèle finale:\n",
    "data_matrix = np.zeros((n_users, n_items))\n",
    "for line in tab[[\"User_ID_new\",\"Item_ID_new\",\"rating\"]].itertuples():#parcourire la ligne col par col\n",
    "    data_matrix[line[1]-1, line[2]-1] = line[3] \n",
    "R = pd.DataFrame(data_matrix)\n",
    "model_user = pairwise_distances(R, metric='cityblock')#meilleur modèle item-citoyblock .T psk c'est item\n",
    "model_item = pairwise_distances(R.T, metric='cityblock')#meilleur modèle item-citoyblock .T psk c'est item\n",
    "\n",
    "R_pred_us=pd.DataFrame(predict(data_matrix, model_user, 'user'))#la prediction\n",
    "R_pred_it=pd.DataFrame(predict(data_matrix, model_item, 'item'))#la prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getrecom_membased_for_user( iduser,n=10,ch=\"all\"):\n",
    "    estim=R_pred_us.loc[iduser-1,R.loc[iduser-1,:] == 0]\n",
    "    donne=R.loc[iduser-1,R.loc[iduser-1,:] > 0]\n",
    "    if ch==\"discover\":\n",
    "        res=estim\n",
    "    else:\n",
    "        res=estim.append(donne)\n",
    "    res=res.sort_values( ascending=False)[0:n]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getrecom_membased_for_item( iditem,n=10,ch=\"all\"):\n",
    "    estim=R_pred_it.T.loc[iditem-1,R.T.loc[iditem-1,:] == 0]\n",
    "    donne=R.T.loc[iditem-1,R.T.loc[iditem-1,:] > 0]\n",
    "    if ch==\"discover\":\n",
    "        res=estim\n",
    "    else:\n",
    "        res=estim.append(donne)\n",
    "    res=res.sort_values( ascending=False)[0:n]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40     5.000000\n",
       "117    4.998489\n",
       "663    4.994203\n",
       "24     4.985279\n",
       "84     4.982837\n",
       "495    4.957466\n",
       "710    4.955156\n",
       "532    4.951005\n",
       "426    4.939143\n",
       "225    4.934024\n",
       "Name: 6372, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(getrecom_membased_for_item(6373,10,\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2139    4.911902\n",
       "1910    4.910203\n",
       "1591    4.900214\n",
       "2457    4.894726\n",
       "3574    4.888690\n",
       "2522    4.884848\n",
       "2235    4.882589\n",
       "813     4.881029\n",
       "1773    4.879601\n",
       "1112    4.879552\n",
       "Name: 729, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(getrecom_membased_for_user(730,10,\"discover\"))#correcte!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Conclusion: \n",
    "-Les modèles Memory based sont  facile à implementer et génére des bonnes résultats.\n",
    "-Ce type de modèle n'est pas scalable (n'est pas vraiment pratique dans un problème d'une grande base de donnée vu qu'il \n",
    "calcule à chaque fois la corrélation entre tous les utilisateur &/| les items) et ne resolut pas le problème de cold start(\n",
    "lorsqu'on commence avec un nouveau utilisateur/item dont on n'a pas assez d'information)\n",
    "Pour répondre au problème de scalability on crée les modele Model Based(partie suivante).\n",
    "Pour répondre au problème de cold start, on utilise la recommandation Content based (on va pas l'utiliser vu qu'on n'a pas ces données )\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Model-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Dans cette partie du projet, nous appliquons le deuxième sous-type du fitrage collaboratif : \"Model-based\". \n",
    "Il consiste à appliquer la matrice de factorisation (MF) : c'est une méthode d'apprentissage non supervisé de décomposition\n",
    "et de réduction de dimensionnalité pour les variables cachées. \n",
    "\n",
    "Le but de la matrice de factorisation est d'apprendre les préférences cachées des utilisateurs et les attributs cachés des items\n",
    "depuis les ratings connus dans notre jeu de données, pour enfin prédire les ratings inconnus en multipliant les matrices de varibales \n",
    "cachées des utilisateurs et des items. \n",
    "\n",
    "Il existe plusieurs techniques de réduction de dimensionnalité dans l'implémentation des systèmes de recommendations. \n",
    "Dans notre projet, nous avons utilisé :\n",
    "- SVD : singular value decomposition\n",
    "- SGD : Stochastic Gradient Descent\n",
    "- NMF(sklearn) : Non-Negative Matrix Factorization\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Singular value decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 La mise en place des SVD:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Cette technique, comme toutes les autres, consiste à réduire la dimensionnalité de la matrice User-Item calculée précedemment.\n",
    "Posons R la matrice User-Item de taille m x n (m : nombre de users, n: nombre d'items) et  k: la dimension de l'espace des caractères cachés.\n",
    "L'équation générale de SVD est données par : \n",
    "R=USV^T\n",
    "\n",
    "- La matrice U des caractères cachés pour les utilisateurs : de taille m*k\n",
    "- La matrice V des caractères cachés pour les items : de taille n*k\n",
    "- La matrice diagonale de taille k x k avec des valeurs réelles non-negatives sur la diagonale\n",
    "\n",
    "On peut faire la prédiction en appliquant la multiplication des 3 matrices\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#Obtenir les composantes de SVD à partir de la matrice User-Item du train. On choisit une valeur de k=20.\n",
    "u, s, vt = svds(train_data_matrix, k = 20)\n",
    "s_diag_matrix=np.diag(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multiplication des 3 matrices avec np.dot pour obtenir la matrice User_Item estimée.\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#la normalisation de X_pred vu qu'elle retourne des données qui sont pas bien distribué dans [0,5]\n",
    "import math\n",
    "x = np.zeros((n_users, n_items))\n",
    "for i in range(0,n_items):\n",
    "    a=max(X_pred[:,i])\n",
    "    b=min(X_pred[:,i])\n",
    "    c=0\n",
    "    d=5\n",
    "    for j in range(0,n_users):\n",
    "        x[j,i]=(X_pred[:,i][j]-(a-c))*d/(b-a+c)\n",
    "        if math.isnan(x[j,i]): x[j,i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.49099012467\n"
     ]
    }
   ],
   "source": [
    "# Calcul de performance avec RMSE entre la matrice estimée et la matrice du test\n",
    "print 'RMSE: ' + str(rmse(x, test_data_matrix))\n",
    "#On a trouvé 1.49 comme RMSE, c'est plus grand que le RMSE des modèles Memory based, mais ça prend énormement moins du temps.\n",
    "#Ce qu'on va dans la partie qui suit c'est d'améliorer notre modèle par le gradient stochastique et l'ALS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. La généralisation du modele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Après avoir implementer et tester notre modele, nous avons implémenté la fonction getrecom_membased() qui permet de recommander des items \n",
    "#à un utilisateur. \n",
    "#créant le modèle sur tout le jeu des données:\n",
    "u, s, vt = svds(data_matrix, k = 20)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt) \n",
    "import math\n",
    "x = np.zeros((n_users, n_items))\n",
    "for i in range(0,n_items):\n",
    "    a=max(X_pred[:,i])\n",
    "    b=min(X_pred[:,i])\n",
    "    c=0\n",
    "    d=5\n",
    "    for j in range(0,n_users):\n",
    "        x[j,i]=(X_pred[:,i][j]-(a-c))*d/(b-a+c)\n",
    "        if math.isnan(x[j,i]): x[j,i]=0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def getrecom_modbased_svd( iduser,n=10,ch=\"all\"):\n",
    "    estim=x.loc[iduser-1,R.loc[iduser-1,:] == 0]#x:la matrice qu'on a prédit\n",
    "    donne=R.loc[iduser-1,R.loc[iduser-1,:] > 0]#R: la matrice qui contient les données sur tout le modèle\n",
    "    if ch==\"discover\":\n",
    "        res=estim\n",
    "    else:\n",
    "        res=estim.append(donne)\n",
    "    res=res.sort_values( ascending=False)[0:n]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103     5.0\n",
       "2131    5.0\n",
       "2183    5.0\n",
       "2187    5.0\n",
       "2401    5.0\n",
       "2457    5.0\n",
       "2633    5.0\n",
       "3956    5.0\n",
       "2814    5.0\n",
       "2863    5.0\n",
       "Name: 79, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recommander l'utilisateur 18 en prenons en compte tous les items y compris ceux qu'il a déjà noté. Afficher les 10 premiers résultats\n",
    "getrecom_modbased_svd(80,10,\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4527    5.000000\n",
       "2626    5.000000\n",
       "2573    5.000000\n",
       "2991    5.000000\n",
       "1523    5.000000\n",
       "2344    4.972864\n",
       "3070    4.948688\n",
       "2701    4.947056\n",
       "2436    4.941400\n",
       "4148    4.937904\n",
       "Name: 17, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recommander l'utilisateur 18 en prenons en compte que les items qu'il n'a pas noté. Afficher les 10 premiers résultats\n",
    "getrecom_modbased_svd(18,10,\"discover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Stochastic Gradient Descent with Weighted Lambda Regularisation (SGD-WR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. La mise en place du modèle:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\"\"\" ********** Algorithme SGD (Stochastic Gradient Descent) ************\n",
    "\n",
    "Quand on utilise le filtrage collboratif pour SGD,on veut estimer 2 matrices P et Q: \n",
    "- La matrice P des caractères cachés pour les utilisateurs : de taille m*k (m: nombre d'utilisateurs, k: dimension de l'espace des caractères cachés)\n",
    "- La matrice Q des caractères cachés pour les items : de taille n*k (m: nombre d'items, k: dimension de l'espace des caractères cachés)\n",
    "\n",
    "Après l'estimation de P et Q, on peut alors prédire les ratings inconnus en multipliant les matrices P et la transposée de Q.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Les matrices I et I2 serviront de matrices de sélecteur pour prendre les éléments appropriés après la création du Train et du Test\n",
    "#selecteur de var est égal à 1 si la valeur dans la matrice est != 0\n",
    "\n",
    "# matrice d'indices pour le train\n",
    "I = train_data_matrix.copy()\n",
    "I[I > 0] = 1\n",
    "I[I == 0] = 0\n",
    "\n",
    "# matrice d'indices pour le test\n",
    "I2 = test_data_matrix.copy()\n",
    "I2[I2 > 0] = 1\n",
    "I2[I2 == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# La fonction prediction permet de prédire les ratings inconnus en multipliant les matrices P et la transposée de Q\n",
    "def prediction(P,Q):\n",
    "    return np.dot(P.T,Q)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Pour mettre à jour P et Q, on peut utiliser le SGD où on itère chaque observation dans le train pour mettre à jour P et Q au fur et à mesure: \n",
    "Q_{i+1} = Q_i + (gamma) (e{ui}*P_u - (lambda)* Q_i)\n",
    "P_{i+1} = P_i + (gamma) (e{ui}*Q_u - (lambda)* P_i)\n",
    "\n",
    "On note: \n",
    "- (gamma) la vitesse de l'apprentissage\n",
    "- (lambda) le Terme de régularisation\n",
    "- e :l'erreur qui est la différence entre le rating réel et le rating prédit.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ****** Initialisation ******* \n",
    "\n",
    "lmbda = 0.1 # Terme de régularisation\n",
    "k = 20 # dimension de l'espace des caractères cachés\n",
    "m, n = train_data_matrix.shape  # nombre d'utilisateurs et d'items\n",
    "steps = 150  # Nombre d'itération \n",
    "gamma=0.001  # vitesse d'apprentissage\n",
    "\n",
    "P = 3 * np.random.rand(k,m) # Matrice des caractères cachés pour les utilisateurs\n",
    "Q = 3 * np.random.rand(k,n) # Matrice des caractères cachés pour les items\n",
    "\n",
    "#les matrices P et Q sont initialisées avec des valeurs aléatoires au début, mais leur contenu change à chaque itération en se \n",
    "#basant sur le train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Il existe plusieurs métriques d'évaluation, mais la plus populaire des métriques utilisée pour évaluer l'exactitude des ratings prédits\n",
    "est l'erreur quadratique moyenne (RMSE) qu'on a utilisé dans notre projet :\n",
    "\n",
    "RMSE =RacineCarrée{(1/N) * sum (r_i -estimé{r_i})^2}\n",
    "\"\"\"\n",
    "\n",
    "def rmse2(I,R,Q,P):\n",
    "    return np.sqrt(np.sum((I * (R - prediction(P,Q)))**2)/len(R[R > 0]))\n",
    "\n",
    "#R = train_data_matrix\n",
    "#prediction(P,Q): estimateur du train_data_matrix avec la méthode de factorisation\n",
    "#I pour prendre seulement la partie significative de la matrice (!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#On ne considère que les valeurs !=0 \n",
    "users,items = train_data_matrix.nonzero()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#implémentation de the SGD-WR: (ps) cet algo prend du temps ça depend de nombre steps choisi.\n",
    "train_errors = [] #stocker les erreurs du train obtenus par RMSE à chaque itération (step) \n",
    "test_errors = [] #stocker les erreurs du test obtenus par RMSE à chaque itération (step) \n",
    "     \n",
    "for step in xrange(steps):\n",
    "    for u, i in zip(users,items): #zip() retourne les tuples (user,item)\n",
    "        e = train_data_matrix[u, i] - prediction(P[:,u],Q[:,i])  # calculer l'erreur e pour le gradient\n",
    "        P[:,u] += gamma * ( e * Q[:,i] - lmbda * P[:,u]) # mise à jour de la matrice P\n",
    "        Q[:,i] += gamma * ( e * P[:,u] - lmbda * Q[:,i])  # mise à jour de la matrice Q\n",
    "        \n",
    "    train_rmse = rmse2(I,train_data_matrix,Q,P) # Calcul de l'RMSE à partir du train\n",
    "    test_rmse = rmse2(I2,test_data_matrix,Q,P) # Calcul de l'RMSE à partir du test\n",
    "    train_errors.append(train_rmse) #à chaque itération ajouter l'erreur à la liste\n",
    "    test_errors.append(test_rmse) #à chaque itération ajouter l'erreur à la liste\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 1.18244470872\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE : ' + str(np.mean(test_errors)) #RMSE = 1.18 ce qui est super! en le comparant avec les autre RMSE (1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGHCAYAAACNjTnqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c4d60b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Maitenant, après avoir obtenus toutes les valeurs de l'erreur à chaque étape,on peut tracer la courbe d'apprentissage.\n",
    "# ==> On Vérifie la performance en traçant les erreurs du train et du test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(steps), train_errors, marker='o', label='Training Data'); \n",
    "plt.plot(range(steps), test_errors, marker='v', label='Test Data');\n",
    "plt.title('Courbe d apprentissage SGD')\n",
    "plt.xlabel('Nombre d etapes');\n",
    "plt.ylabel('RMSE');\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Le modèle semble fonctionner bien avec,relativement, une basse valeur de RMSE après convergence.\n",
    "La performance du modèle peut dépendre des paramètres (gamma), (lambda) et k qu'on a varié à plusieurs reprises afin d'obtenir \n",
    "le meilleur RMSE.\n",
    "\n",
    "Après cette étape, on peut comparer le rating réel avec le rating estimé; Pour ce faire, on utilise la matrice User-item qu'on a \n",
    "déjà calculée et utilisé la fonction prediction(P,Q) implémentée précédemment. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 La généralisation de ce modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "random.seed(123)\n",
    "P = 3 * np.random.rand(k,m) \n",
    "Q = 3 * np.random.rand(k,n)\n",
    "train_errors = [] \n",
    "test_errors = []\n",
    "for step in xrange(steps):\n",
    "    for u, i in zip(users,items): #zip() retourne les tuples (user,item)\n",
    "        e = data_matrix[u, i] - prediction(P[:,u],Q[:,i])  # calculer l'erreur e pour le gradient\n",
    "        P[:,u] += gamma * ( e * Q[:,i] - lmbda * P[:,u]) # mise à jour de la matrice P\n",
    "        Q[:,i] += gamma * ( e * P[:,u] - lmbda * Q[:,i]) \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R_pred=prediction(P,Q)\n",
    "x = np.zeros((n_users, n_items))\n",
    "for i in range(0,n_items):\n",
    "    a=max(R_pred[:,i])\n",
    "    b=min(R_pred[:,i])\n",
    "    c=0\n",
    "    d=5\n",
    "    for j in range(0,n_users):\n",
    "        x[j,i]=(R_pred[:,i][j]-(a-c))*d/(b-a+c)\n",
    "        if math.isnan(x[j,i]): x[j,i]=0\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recommander des items pour un utilisateur donné:\n",
    "x=pd.DataFrame(x)\n",
    "def getrecom_modbased_sgd( iduser,n=10,ch=\"all\" ):\n",
    "    estim=x.loc[iduser-1,R.loc[iduser-1,:] == 0]\n",
    "    donne=R.loc[iduser-1,R.loc[iduser-1,:] > 0]\n",
    "    if ch==\"discover\":\n",
    "        res=estim\n",
    "    else:\n",
    "        res=estim.append(donne)\n",
    "    res=res.sort_values( ascending=False)[0:n]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855     5.0\n",
       "202     5.0\n",
       "942     5.0\n",
       "225     5.0\n",
       "1029    5.0\n",
       "866     5.0\n",
       "1042    5.0\n",
       "204     5.0\n",
       "1053    5.0\n",
       "255     5.0\n",
       "Name: 17, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recommander l'utilisateur 18 en prenons en compte tous les items y compris ceux qu'il a déjà noté. Afficher les 10 premiers résultats\n",
    "getrecom_modbased_sgd(18,10,\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5902    4.649808\n",
       "3246    4.625329\n",
       "572     4.615001\n",
       "4167    4.592095\n",
       "2219    4.590571\n",
       "5562    4.588044\n",
       "4481    4.586026\n",
       "3240    4.578914\n",
       "5164    4.578659\n",
       "2440    4.574947\n",
       "Name: 17, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recommander l'utilisateur 18 en prenons en compte que les items qu'il n'a pas noté. Afficher les 10 premiers résultats\n",
    "getrecom_modbased_sgd(18,10,\"discover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.3. Non-Negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Nous restons ici dans le deuxième sous-type du fitrage collaboratif : \"Model-based\"en utilisant la matrice de factorisation.\n",
    "Mais cette fois-ci nous utilisons NMF (Non-Negative Matrix Factorization) de sklearn pour l'appliquer\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta=1, eta=0.1, init='random', l1_ratio=0.0, max_iter=200,\n",
       "  n_components=5, nls_max_iter=2000, random_state=0, shuffle=False,\n",
       "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Utilisation de la fonction NMF de sklearn. Ajustement du modèle avec le Train\n",
    "from sklearn.decomposition import NMF\n",
    "nmf_model = NMF(n_components=5, init='random', random_state=0)\n",
    "nmf_model.fit(train_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Obtention des matrices P et Q(Transposée) à partir du Test \n",
    "P = nmf_model.transform(test_data_matrix);\n",
    "Q_T = nmf_model.components_;\n",
    "\n",
    "#Calcul de la matrice user_item estimée en multipliant les matrice P et Q(Transposée)\n",
    "nR = np.dot(P, Q_T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.zeros((n_users, n_items))\n",
    "for i in range(0,n_items):\n",
    "    a=max(nR[:,i])\n",
    "    b=min(nR[:,i])\n",
    "    c=0\n",
    "    d=5\n",
    "    for j in range(0,n_users):\n",
    "        x[j,i]=(nR[:,i][j]-(a-c))*d/(b-a+c)\n",
    "        if math.isnan(x[j,i]): x[j,i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7395234803101045"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(x, test_data_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Index matrix for training data\n",
    "I = train_data_matrix.copy()\n",
    "I[I > 0] = 1\n",
    "I[I == 0] = 0\n",
    "\n",
    "# Index matrix for test data\n",
    "I2 = test_data_matrix.copy()\n",
    "I2[I2 > 0] = 1\n",
    "I2[I2 == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps: on n'a pas commenté car c'est presque le mm principe que le modele SGD!\n",
    "lmbda = 0.1 \n",
    "k = 20 \n",
    "n_epochs = 2 # Nombre d'étapes\n",
    "m, n = train_data_matrix.shape # Number of users and items\n",
    "P = 3 * np.random.rand(k,m) # Latent user feature matrix\n",
    "Q = 3 * np.random.rand(k,n) # Latent item feature matrix\n",
    "Q[0,:] = train_data_matrix[train_data_matrix != 0].mean(axis=0) # Avg. rating for each movie\n",
    "E = np.eye(k) # (k x k)-dimensional idendity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730L, 6373L)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/2] train error: 1.064051, test error: 1.305094\n",
      "[Epoch 2/2] train error: 0.779620, test error: 1.133827\n",
      "Algorithm converged\n"
     ]
    }
   ],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "# Repeat until convergence\n",
    "for epoch in range(n_epochs):\n",
    "    # Fix Q and estimate P\n",
    "    for i, Ii in enumerate(I):\n",
    "        nui = np.count_nonzero(Ii) # Number of items user i has rated\n",
    "        if (nui == 0): nui = 1 # Be aware of zero counts!\n",
    "    \n",
    "        # Least squares solution\n",
    "        Ai = np.dot(Q, np.dot(np.diag(Ii), Q.T)) + lmbda * nui * E\n",
    "        Vi = np.dot(Q, np.dot(np.diag(Ii), train_data_matrix[i].T))\n",
    "        P[:,i] = np.linalg.solve(Ai,Vi)\n",
    "        \n",
    "    # Fix P and estimate Q\n",
    "    for j, Ij in enumerate(I.T):\n",
    "        nmj = np.count_nonzero(Ij) # Number of users that rated item j\n",
    "        if (nmj == 0): nmj = 1 # Be aware of zero counts!\n",
    "        \n",
    "        # Least squares solution\n",
    "        Aj = np.dot(P, np.dot(np.diag(Ij), P.T)) + lmbda * nmj * E\n",
    "        Vj = np.dot(P, np.dot(np.diag(Ij), train_data_matrix[:,j]))\n",
    "        Q[:,j] = np.linalg.solve(Aj,Vj)\n",
    "    \n",
    "    train_rmse = rmse2(I,train_data_matrix,Q,P)\n",
    "    test_rmse = rmse2(I2,test_data_matrix,Q,P)\n",
    "    train_errors.append(train_rmse)\n",
    "    test_errors.append(test_rmse)\n",
    "    \n",
    "    print \"[Epoch %d/%d] train error: %f, test error: %f\" \\\n",
    "    %(epoch+1, n_epochs, train_rmse, test_rmse)\n",
    "    \n",
    "print \"Algorithm converged\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Conclusion:\n",
    "Cet algorithme est le meilleur de tous les autres algorithmes. \n",
    "Dans 2 itération on a trouvé une erreur de train qui est égale à x et une erreur de test qui est égale à y\n",
    "Comme c'est l'algorithme le plus rapide et le plus efficace, On a décidé de le généralisé sur tout le jeu de données.\n",
    "Vu qu'on a dépassé les limites de RAM pour python(on ne peut pas construire une matrice d'un taille 7636 lignes et 1264 colonnes), \n",
    "Ce qui a résoulu notre problème vite fait!\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
